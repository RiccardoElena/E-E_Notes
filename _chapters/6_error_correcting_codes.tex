\chapter{Codici correttori d'errori}

Fino a ora per quanto riguarda la codifica di canale abbiamo dato una descrizione astratta di alcune proprietà, senza entrare nel dettaglio di come costruire effettivamente dei codici che permettano di correggere gli errori introdotti dal canale.
Andiamo a vedere ora come costruire tali codici.

Da ora in poi si assumerà che qualsiasi codifica sia su alfabeto binario.

\begin{definition}{Distanza di Hamming in \(\set{0,1}^n\)}
  La \keyword{distanza di Hamming} tra due stringhe binarie \(x,y \in \set{0,1}^n\) è il numero di posizioni in cui le due stringhe differiscono, ovvero
  \[d(x,y) = \sum_{i=1}^n \abs{x_i - y_i}\]
  dove \(x=x_1\ldots x_n\) e \(y=y_1\ldots y_n\).
\end{definition}

La distanza di Hamming è una vera e propria metrica, infatti \(\forall x,y,z \in \set{0,1}^n\)
\begin{enumerate}
  \item \(d(x,y) = d(y,x)\)
  \item \(d(x,y) \geq 0\) e \(d(x,y) = 0 \iff x=y\)
  \item \(d(x,z) \leq d(x,y) + d(y,z)\) (disuguaglianza triangolare)
\end{enumerate}

\begin{proposition}{}
  Su un canale binario simmetrico con probabilità di errore \(q\) usato senza feedback, si ha che
  \[\forall x,y \in \set{0,1}^n, p(y|x) = q^{d(x,y)} {(1-q)}^{n-d(x,y)}\]
\end{proposition}
\begin{proof}
  Basta ricordare che \(p(y|x) = \prod_{i=1}^n p(y_i|x_i)\) e che \(p(y_i|x_i) = q\) se \(y_i \neq x_i\) e \(1-q\) altrimenti.
  Ovviamente il numero di posizioni in cui \(y_i \neq x_i\) è proprio \(d(x,y)\) e quello in cui \(y_i = x_i\) è \(n-d(x,y)\).
\end{proof}

\section{Scelta della decodifica}

Dato un canale con caratteristiche note, e una funzione di codifica \(f: \mathcal{W} \to \set{0,1}^n\), idealmente dovremmo scegliere \(g\) che minimizzi gli errori.
Dato \(y \in \set{0,1}^n\), avrebbe senso porre \(g(y) = f^{-1}(x)\), dove \(x\in\set{0,1}^n\) massimizza \(p(x|y)\), ma ciò richiederebbe di conoscere la distribuzione di \(W\), visto che \(p(x|y) = \frac{p(x,y)}{p(y)} = \frac{p(x)p(y|x)}{p(y)}\), ma in generale il ricevente conosce solo le proprietà del canale (ovvero \(p(y|x)\)).

Una soluzione \qi{pratica} è quella di scegliere \(g(y) = f^-1(x)\) dove \(x\) massimizza \(p(y|x)\).
Un altra possibile scelta consiste nel minimizzare \(d(x,y)\).

\begin{proposition}{}
  Su un canale binario simmetrico usato senza feedback con probabilità di errore \(q \leq \frac{1}{2}\) le due strategie coincidono, ovvero
  \[p(y|x) = \max_{x' \in f(\mathcal{W})} p(y|x') \iff d(x,y) = \min_{x' \in f(\mathcal{W})} d(x',y)\]
\end{proposition}

\begin{proof}{}
  Siano \(x,x' \in f(\mathcal{W})\), \(j=d(x,y), j'=d(x',y)\). Allora
  \[\frac{p(y|x)}{p(y|x')} = \frac{q^j{(1-q)}^{n-j}}{q^{j'}{(1-q)}^{n-j'}} = {\left(\frac{1-q}{q}\right)}^{j'-j}\]
  Essendo \(q < \frac{1}{2}\), allora \(\frac{1-q}{q} > 1\) e dunque \(\frac{1-q}{q} > 1\).

  E dunque \[\frac{p(y|x)}{p(y|x')} > 1 \iff j' - j > 0 \iff j < j'\]
\end{proof}

\begin{observation}{}
  A seconda della seconda del codice \(Z = f(\mathcal{W})\) utilizzato, potrebbero esserci più \(x \in \mathcal{Z}\) aventi distanza minima da \(y \in \mathcal{Y}\).
  \begin{example}{}
    Sia \(Z = \set{0^8,00111100,11 0^5 1,0^4 1^3 0,101^3 001,00110110,11001011}\) e \(y = 11001001\). Allora chiaramente \(y \not\in \mathcal{Z}, (\forall x \in \mathcal{Z}, d(x,y)\neq 0)\), ma sia \(x=110^5 1\) che \(x' = 11001011\) danno \(d(x,y)=d(x',y) = 1\).
  \end{example}

  Di conseguenza è necessario aggiungere criteri ulteriori per risolvere le ambiguità.
\end{observation}

\begin{definition}{Minima distanza di un codice}
  Dato un codice uniforme \(Z\subseteq \set{0,1}^n\), chiamiamo \keyword{minima distanza di \(Z\)} la  quantità
  \[\delta_Z = \min_{\substack{x,x' \in Z \\ x\neq x'}} d(x,x')\]
\end{definition}

\begin{example}{}
  Prendendo \(Z\) dall'esempio precedente, si ha che \(\delta_Z = 3\).
\end{example}

\begin{definition}{Intorno}
  Dato \(x \in \set{0,1}^n\) e \(r \geq 0\), definiamo l'\keyword{intorno di raggio \(r\) centrato in \(x\)} come
  \[N_r(x) = \set{y \in \set{0,1}^n : d(x,y) \leq r}\]
\end{definition}

Vediamo dunque un risultato in cui queste definizioni vanno insieme.

\begin{lemma}{}
  Dato \(Z\subseteq\set{0,1}^n\) con \(\delta_Z \geq 2r+1\) per un certo \(r\geq 0\), allora
  \[\forall x,x' \in Z, x\neq x' \implies N_r(x) \cap N_r(x') = \emptyset\]
\end{lemma}

\begin{proof}
  Siano \(z,z' \in Z\) e assumiamo che \(N_r(z) \cap N_r(z') \neq \emptyset\) e sia dunque \(u \in \N_r(z) \cap N_r(z')\).
  Allora dalla disuguaglianza triangolare si ha che
  \[d(z,z') \leq d(z,u) + d(u,z') \leq r + r = 2r\]
  Dunque abbiamo trovato due parole \(z,z' \in Z\) con distanza minore della distanza minima del codice, dunque \(z=z'\).
\end{proof}

\begin{theorem}{}
  Sia \(Z = f(\mathcal{W})\) codice binario uniforme con \(\delta_Z \geq 2r+1\) per un certo \(r\geq 0\), trasmesso su un BSC con probabilità di errore \(q\leq \frac{1}{2}\) usato senza feedback.
  Allora usando la strategia della minima distanza, ogni output con al più \(r\) errori è decodificato correttamente.
\end{theorem}

\begin{proof}{}
  Sia \(x \in f(\mathcal{W})\) e sia \(y \in N_r(x)\) l'output ricevuto.
  Dal lemma precedente, \(\forall x' \in Z\setminus\set{x}, N_r(x) \cap N_r(x') = \emptyset\) e dunque \(y \not\in N_r(x')\) da cui \(d(x',y) > r\).
  Dunque \(d(x,y) < d(x',y)\) e quindi la decodifica tramite minima distanza imporrà \(g(y) = f^{-1}(x)\).
\end{proof}

\begin{definition}{Codice correttore di errori}
  Chiamiamo \keyword{codice correttore di errori} un codice binario uniforme \(Z\subseteq \set{0,1}^n\) con \(\delta_Z \geq 2r+1\) per un certo \(r\geq 0\).
  Tale codice è in grado di correggere fino a \(r\) errori.
\end{definition}

\begin{theorem}{Limite di Hamming}
  Sia \(Z \subseteq \set{0,1}^n\) un codice correttore di errori in grado di correggere fino a \(r\) errori.
  Allora
  \[\#Z \leq \frac{2^n}{\sum_{i=0}^r {n \choose i}}\]
\end{theorem}

\begin{proof}
  Dati \(x \in \set{0,1}^n\) e \(j\leq n\), le parole a distanza esattamente \(j\) da \(x\) sono ottenute cambiando \(j\) bit delle \(n\) posizioni di \(x\), e dunque sono esattamente \({n \choose j} = \frac{n!}{j!(n-j)!}\).

  Allora \(\#N_r(x) = \sum_{i=0}^r {n \choose i}\). Al variare di \(z \in Z\), gli intorni \(N_r(z)\) sono a due a due disgiunti per \(r \leq \frac{\delta_Z - 1}{2}\).
  Dunque 
  \[\#\bigcup_{z\in Z} N_r(z)= \sum_{z\in Z} \sum_{i=0}^r {n \choose i} = \#Z \cdot \sum_{i=0}^r {n \choose i}\leq \# \set{0,1}^n = 2^n\]
  Ovvero \[\# Z \leq \frac{2^n}{\sum_{i=0}^r {n \choose i}}\] 
\end{proof}

\begin{example}{}
  Supponiamo di voler identificare \(100\) elementi tramite stringhe binarie di lunghezza \(n\). Quanto grande deve essere \(n\) affinché il codice risultante corregga \(2\) errori?

  Usando il limite di Hamming, dobbiamo avere che
  \[100 \sum_{i=0}^2{n \choose j} \leq  2^n \iff 100 (1+n+\frac{n(n-1)}{2})\leq 2^n\]
  Dunque semplificando
  \[50(n^2+n+2)\leq 2^n \implies n \geq 14\]
\end{example}

\begin{observation}{}
  Quando usiamo un codice binario per trasmettere su un canale la cardinalità del codice e \(n\) sono legati al tasso di trasmissione \(R = \frac{\log \#\mathcal{W}}{n} = \frac{\log \#Z}{n}\).
  Il limite di Hamming esprime compensazione tra tasso ed errori corretti.

  Dunque se si vuole correggere più errori, si deve ridurre il tasso di trasmissione.
\end{observation}

\section{Codici lineari su \(\mathbb{F}_2\)}

Avendo limitato la trattazione ai soli codici binari, possiamo sfruttare la struttura algebrica del campo finito \(\mathbb{F}_2 = \set{0,1}\) con le operazioni di somma e moltiplicazione modulo \(2\).

Di conseguenza \(\set{0,1}^n\) è uno spazio vettoriale \(n\)-dimensionale su \(\mathbb{F}_2\) con le operazioni di somma e prodotto scalare definite componente per componente.

\begin{definition}{Codici lineari}
  Un codice \(Z \subseteq \set{0,1}^n\) è \keyword{lineare} se è un sottospazio vettoriale di \(\mathbb{F}_2^n\), cioè se e solo se
  \[\forall x,x'\in Z, x+x'\in Z \]
\end{definition}

Normalmente per verificare che \(Z \subseteq \mathbb{F}_2^n\) è un sottospazio vettoriale sarebbe necessario verificare che \((Z, +)\) è un sottogruppo di \((\mathbb{F}_2^n,+)\) e che \(Z\) è chiuso rispetto al prodotto scalare.
Come esposto nella definizione però, nel caso di \(\mathbb{F}_2\) è sufficiente verificare la chiusura rispetto alla somma.

Questo poiché per far si che \((Z,+)\) sia sottogruppo è necessario e sufficiente che sia chiuso rispetto alla somma, come richiesto, che contenga l'elemento neutro \(\underline{0}\) e che ogni elemento abbia l'inverso.
Ma in \(\mathbb{F}_2\), si ha che \(x+x=0\) per ogni \(x\), dunque se \((Z,+)\) è chiuso rispetto alla somma, allora contiene lo zero e ogni elemento è il proprio inverso, ovvero è automaticamente un sottogruppo.

Per il prodotto scalare, essendo gli unici scalari \(0\) e \(1\), si ha che per ogni \(x \in Z\), \(1\cdot x = x \in Z\) e \(0\cdot x = \underline{0} \in Z\), dunque anche la chiusura rispetto al prodotto scalare è automatica.

Un codice lineare \(Z\) è caratterizzato dai parametri \((n,k,\delta)\) dove \(n\) è la lunghezza delle parole del codice, \(\delta\) è la minima distanza del codice, e \(k\) è la dimensione del sottospazio vettoriale \(Z\).
Ovviamente su un campo finito di cardinalità \(q\) si ha che \(\#Z = q^k\), dunque nel nostro caso \(\#Z = 2^k\).

\begin{definition}{peso}
  Dato \(x \in \set{0,1}^n\), definiamo il \keyword{peso} di \(x\) come il numero di occorrenze di \(1\) in \(x\), ovvero
  \[w(x) = \sum_{i=1}^n x_i\]
\end{definition}

\begin{proposition}{}
  Se \(Z\) è un codice lineare, allora \(\delta_Z = \min_{x\in Z\setminus\set{\underline{0}}} w(x)\)
\end{proposition}
%todo : questa prova è inutilmente controrta. Problema di trascrizione, è semplicissima!
\begin{proof}
  Essendo \(Z\) un sottospazio vettoriale, \(\underline{0}\in Z\).
  Dunque, dato \(x\in Z\setminus\set{\underline{0}}\) si ha che \(d(x,\underline{0}) = w(x)\), e dati \(x,x' \in Z \st x\neq x'\) si può notare che
  \[d(x,x') = w(x+x')\]
  Questo poiché \(x+x'\) ha \(1 = 0 +1 = 1+ 0\) esattamente nelle posizioni in cui \(x\) e \(x'\) differiscono e \(0 = 0 +0 = 1+1\) dove sono uguali.
  Essendo \((Z,+)\) un gruppo, l'unico inverso di \(x\) è \(x\) stesso, dunque \(x\neq x' \implies x+x'\neq \underline{0}\).

  Dunque pesi (di elementi non nulli) e distanza (di elementi diversi) coincidono e in particolare, hanno lo stesso minimo.
\end{proof}

\begin{definition}{Nucleo (Kernel)}
  Un codice lineare \(Z\) di dimensione \(k\) è \keyword{nucleo (kernel)} di una matrice \(H\) di dimensione \(n-k \times n\), \(Z = \ker H\) tale che
  \[z \in Z \iff H z^T = 0\]

  Viceversa, se \(H\) è una matrice binaria con \(n\) colonne, il suo nucleo \(\ker H\) è un codice lineare di dimensione \(n-rank(H)\).

  La matrice \(H\) è detta \keyword{matrice di controllo} del codice \(Z= \ker H\).
\end{definition}

\begin{note}{}
  Essendo in \(\mathbb{F}_2^n\), preso \(y \in \mathbb{F}_2^n\), \(Hy^T\) è la somma delle colonne di \(H\) nelle posizioni in cui \(y\) ha \(1\).
\end{note}

\begin{example}{}
  Data la matrice
  \[H = \begin{pmatrix}
    1 & 1 & 0 & 1 & 0 & 0 \\
    0 & 1 & 1 & 0 & 1 & 0 \\
    1 & 0 & 1 & 0 & 0 & 1
  \end{pmatrix}\]
  allora il codice lineare \(Z = \ker H\) si ottiene risolvendo un sistema lineare
  
  \[\begin{cases}
    x_1 + x_2 + x_4 = 0 \\
    x_2 + x_3 + x_5 = 0 \\
    x_1 + x_3 + x_6 = 0
  \end{cases} \implies \begin{cases}
    x_4 = x_1 + x_2 \\
    x_5 = x_2 + x_3 \\
    x_6 = x_1 + x_3
  \end{cases}\]

  ottenendo così \(\ker H = \set{x \in \mathbb{F}_2^6}[x_4=x_1+x_2 \land x_5 = x_2+x_3\land x_6 = x_1+x_3]\)

  Tale matrice è espressa in \keyword{forma standard}, ovvero le ultime \(n-k\) colonne formano la matrice identica. 
  
  Questo fa in modo che gli ultimi \(n-k\) bit di ogni parola del codice siano combinazione lineare dei primi \(k\) bit, e dunque sono determinati dai primi \(k\) bit.

  Si ha dunque che \(Z = \set{\underline{0}, 001011,010110,100101,011101,101110,110011,111000}\) con parametri \((6,3,3)\).
\end{example}

\begin{theorem}{}
  Un codice lineare \(Z\) con matrice di controllo \(H\) corregge almeno \(1\) errore se e solo se le colonne di \(H\) sono a due a due distinte e non nulle.
\end{theorem}

\begin{proof}{}
  Poter correggere almeno un errore come detto in precedenza è necessario che \(\delta_Z \geq 3\).
  Dunque, dimostriamo che per \(\delta_Z < 3\) le colonne di \(H\) non sono a due a due distinte o c'è una colonna nulla, e viceversa.

  \(Z\) ha \(\delta_Z = 1\) se e solo se \(\exists 1 \leq j \leq n\) tale che \(\underline{e}_j = 0\ldots 0 1 0 \ldots 0 \in Z\), dove l'unico \(1\) è in posizione \(j\).
  Allora \(H \underline{e}_j^T = \underline{0}\), e dunque la colonna \(j\) di \(H\) è nulla.

  \begin{note}{}
    \(H \underline{e}_j^T = \underline{0}\) se e solo se la combinazione lineare delle righe di \(H\) con coefficienti presi da \(\underline{e}_j\) è nulla.
    Essendo che \(\underline{e}_j\) ha tutti zeri tranne in posizione \(j\), la combinazione lineare è proprio la colonna \(j\) di \(H\).

    Dunque \(H \underline{e}_j^T = \underline{0} \iff\) colonna \(j\) di \(H\) è nulla.
  \end{note}

  Invece, \(\delta_Z = 2\) se e solo se esistono \(i,j \in \set{1, \ldots, n}\) tali che \(i\neq j\) e \(\underline{e}_i + \underline{e}_j \in Z\).

  \begin{note}{}
    \[\underline{e}_i + \underline{e}_j \in Z \centernot\implies \underline{e}_i \in Z \lor \underline{e}_j \in Z\]
    Se fosse così, avremmo \(\delta_Z = 1\).
  \end{note}

  Quindi 
  \[H{(\underline{e}_i + \underline{e}_j)}^T = \underline{0} \iff H\underline{e}_i^T + H\underline{e}_j^T = \underline{0} \iff H\underline{e}_i^T = H\underline{e}_j^T\]
  perché \(1 = -1\) in aritmetica modulo \(2\).

  Dunque le colonne \(i\) e \(j\) di \(H\) sono uguali.
\end{proof}

La matrice di controllo può essere usata per rilevare e correggere gli errori.
Infatti un vettore \(y\) ricevuto all'invio di \(x\) con errore in posizione \(j\) può essere scritto come \(y = x + \underline{e}_j\).
Allora calcolando \(H y^T = H {(x + \underline{e}_j)}^T = H x^T + H \underline{e}_j^T = H \underline{e}_j^T\) si ottiene la colonna \(j\) di \(H\), indicando così la posizione dell'errore.

\begin{definition}{sindrome}
  Dato un codice lineare \(Z\) con matrice di controllo \(H\), definiamo la \keyword{sindrome} di un vettore \(y \in \set{0,1}^n\) come
  \[S(y) = H y^T\]
\end{definition}

Si ha dunque che:
\begin{itemize}
  \item \(\underline{0}\) è la sindrome di ogni \(x \in Z\)
  \item Le colonne di \(H\) sono le sindromi dei vettori contenenti un singolo errore rispetto a una parola di \(Z\).
  \item \(u,v \in \mathbb{F}_2^n\) hanno la stessa sindrome se e solo se \(u=v + z\) per qualche \(z \in Z\), dato che \(Hu^T=Hv^T \iff H(u^T+v^T) = \underline{0}\)
  \item Dato \(y \in \mathbb{F}_2^n\), l'insieme delle parole con la stessa sindrome di \(y\) è detto \keyword{laterale} \[y+Z = \set{y+z}[z \in Z]\]
  \item I laterali sono a due a due disgiunti e la loro unione è \(\mathbb{F}_2^n\).\footnote{I laterali formano una partizione di \(\mathbb{F}_2^n\), e \(Z\) è la classe di equivalenza di \(\underline{0}\).}
\end{itemize}

Anche le sindromi possono essere usate per decodificare messaggi correggendo errori.
A ogni sindrome infatti corrisponde un laterale, e compilando una tabella a cui a ogni sindrome si associa un rappresentante \(v\) di peso minimo del laterale corrispondente, si può decodificare ogni \(y \in \mathbb{F}_2^n\) come (antimmagine di) \(y + v\).

\begin{proposition}{}
  La decodifica tramite sindrome coincide con la decodifica tramite minima distanza, cioè dato un \(y\in \mathbb{F}_2^n\) appartenente alla sindrome \(y+Z\) con rappresentante minimo \(v\), 
  si ha che \(y+v\) è la parola di codice più vicina a \(y\).
\end{proposition}

\begin{proof}
  Per definizione, \(y\) e \(v\) hanno la stessa sindrome, dunque \(y+v \in Z\).
  Va quindi dimostrato che tra le parole di codice, \(y+v\) è la più vicina a \(y\).
  Presa dunque una parola di codice \(z \in Z\), si ha che \(y + z \in y + Z\), e dunque che \(w(v) \leq w(y + z) = d(y,z)\) per minimalità di \(v\).

  Essendo però che \(\forall x \in Z, x+x = 0\), si ha che \(w(v) = w(y+v+y)=d(y,y+v)\). Possiamo dunque scrivere che, prendendo qualsiasi parola di codice \(z \in Z\) si ha

  \[d(y,v+y) = w(y+v+y) = w(v) \leq w(y + z) = d(y,z)\]

  Dunque \(y+v \in Z\) è la parola di \(Z\) a distanza minimale da \(y\).
\end{proof}


\begin{example}[label=ex:syndromes]{}
  Sia 
  \[H=\begin{pmatrix}
    1 & 0 & 1 & 0 & 0\\
    1 & 1 & 0 & 1 & 0\\
    0 & 1 & 0 & 0 & 1
  \end{pmatrix}\]

  Dal sistema
  \[\begin{cases}
    x_1+x_3 = 0
    x_1+x_2 +x_4=0
    x_2+x_5 = 0
  \end{cases} \implies
  \begin{cases}
    x_1 = x_3
    x_1 + x_2 = x_4
    x_2 = x_5
  \end{cases}\]

  Si ottiene \(\ker H = \set{x \in \mathbb{F}_2^5}[x_1 = x_3, x_1 + x_2 = x_4, x_2 = x_5]\), ovvero \(Z = \ker H = \set{\underline{0}, 01011,10110,11101}\).
  Si ha che la tabella delle sindromi è quella riportata in \Cref{tab:syndromes}

  Ricevendo \(y = 10111\), calcoliamo la sindrome \(Hy^T = {(001)}^T\) e quindi decodifico interpretando \(y\) come \(y + 00001 = 10110 \in \Z\).
\end{example}

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c|c|c}
      Sindrome & Rappresentante & Peso \\
      \hline
      \(000\) & \(00000\) & \(0\) \\
      \(110\) & \(10000\) & \(1\) \\
      \(011\) & \(01000\) & \(1\) \\
      \(100\) & \(00100\) & \(1\) \\
      \(010\) & \(00010\) & \(1\) \\
      \(001\) & \(00001\) & \(1\) \\
      \(101\) & \(00101\) & \(2\) \\
      \(111\) & \(10001\) & \(2\) \\
    \end{tabular}
  \end{center}
  \caption{Tabella delle sindromi e dei rappresentati dei laterali per l'\Cref{ex:syndromes}}\label{tab:syndromes}
\end{figure}

\subsection{Codici di Hamming}

\begin{definition}{}
  Un codice lineare \(Z\)  è detto \keyword{codice di Hamming} se la sua matrice di controllo \(H\) ha per colonne \textbf{tutti} i vettori non nulli di \(\mathbb{F}_2^{n-k}\).

  In particolare deve aversi \(n = 2^{n-k} - 1\).
\end{definition}


Un codice di Hamming ha \(\delta = 3\) poiché prese tre colonne di \(H\) che condividano i primi \(n-k-2\) bit escluse quella che si conclude con \(000\) queste sommano a \(\underline{0}\).
Di conseguenza il vettore formato da tutti \(0\), e \(1\) solo nelle \(3\) posizioni di queste colonne farà parte del codice, poiché dal prodotto con \(H\) rimarrà solo la somma delle colonne scelte prima.
Tale elemento ha ovviamente peso \(3\) e dunque la \(\delta = 3\).
Di conseguenza, i codici di Hamming sono caratterizzati da soli due parametri, \(n\) e \(k\), e sono in grado di correggere un errore.

\begin{theorem}{}
  I codici di Hamming sono \keyword{codici perfetti}, cioè
  \[\forall y \in \mathbb{F}_2^n,\exists!x\in Z\st y \in N_1(x)\]

  In altre parole, \(\bigcup_{x \in Z} N_1(x) = \mathbb{F}_2^n\), ed essendo gli insiemi \(N_1(x)\) a due a due disgiunti, formano una partizione.
\end{theorem}

\begin{proof}
  Ci sono \(2^k\) parole di codice, essendo il numero di variabili libere del sistema che lo ha generato, e ciascun intorno di raggio \(1\) contiene \(n+1\) parole, ovvero la parola stessa e quelle che differiscono su uno solo degli \(n\) bit.
  
  Essendo gli intorni a due a due disgiunti si ha che \(\#\bigcup_{x \in Z}N_1(x) = 2^k(n+1) \).
  
  Per definizione di codice di Hamming, si ha che \(n = 2^{n-k}-1\), dunque \(\#\bigcup_{x \in Z}N_1(x) = 2^k(2^{n-k}) = 2^n = \#\mathbb{F}_2^n\).

  Dunque ogni parola di \(\mathbb{F}_2^n\) appartiene ad almeno un intorno.
\end{proof}

A differenza dei normali codici lineari in cui risultava conveniente avere la matrice di controllo in forma standard,
per i codici di Hamming risulta più convenienti avere \(H\) con le colonne in ordine lessicografico crescente da sinistra a destra.

In tal modo i bit di controllo (ovvero quelli che dipendono dagli altri) hanno indice \(2^i\), con \(i=0,\ldots,n-k-1\).

\begin{example}{}
  La matrice di controllo del codice di Hamming \((7,4)\) è
  \[H = \begin{pmatrix}
    0 & 0 & 0 & 1 & 1 & 1 & 1 \\
    0 & 1 & 1 & 0 & 0 & 1 & 1 \\
    1 & 0 & 1 & 0 & 1 & 0 & 1
  \end{pmatrix}\]
  Avendola in questa forma il sistema
  \[\begin{cases}
    x_4 + x_5 + x_6 + x_7 = 0 \\
    x_2 + x_3 + x_6 + x_7 = 0 \\
    x_1 + x_3 + x_5 + x_7 = 0
  \end{cases}\]
  è risolto dal codice
  \[Z = \set{x \in \mathbb{F}_2^7}[x_1=x_3+x_5+x_7 \land x_2 = x_3 + x_6 + x_7 \land x_4 = x_5 + x_6 + x_7]\]
  e dunque le variabili dipendenti sono in posizioni potenze di \(2\).
  In tal modo, la sindrome di una parola \(y\) è l'espressione binaria del bit da cambiare per correggere l'errore.
\end{example}

Valutando infine i codici visti nel cercare di raggiungere i limiti descritti nel \Cref{thm:shannon_2}, andiamo a valutarne il tasso di trasmissione la capacità di correggere errori (ovvero di abbassare la probabilità di errore).

Preso un qualsiasi codice \(Z \subseteq \mathbb{F}_2^n\), il tasso di trasmissione sarà \(R = \frac{\log \# Z}{2}\).

Se \(Z\) è lineare di parametri \((n,k,\delta)\) possiamo essere più precisi, poiché \(\# Z = 2^k\), dunque \(R = \frac{k}{n}\).

Se inoltre \(Z\) è di Hamming, allora \(n = 2^m -1\) e \(k = n - m\), fissato \(m = n-k\). Abbiamo dunque che il tasso \(R = \frac{n-m}{n} = 1 - \frac{m}{2^m-1}\).
% TODO: fatti spiegare meglio questa conclusione.
Dunque \(\lim_{m\to\infty} R = 1\), ma correggendo solo \(1\) errore non è possibile avere probabilità di errore arbitrariamente basse.

Per provare dunque a raggiungere i limiti descritti a Shannon, l'idea è quella di introdurre ridondanza, in maniera però da mantenere un tasso di trasmissione \(R\) vicino a \(1\).

Un modo naïve per aggiungere ridondanza è considerare il caso \(Z = \set{0^n, 1^n}\). Tale codice ha \(\delta = n\) ma avendo \(k = 1\) si ha che \(R = \frac{1}{n}\), e dunque il tasso di trasmissione tende a \(0\) all'aumentare di \(n\).

\subsection{Codici ciclici}

\begin{definition}{Codici ciclici}
  Un codice \(Z \subseteq \set{0,1}^n\) lineare è detto \keyword{ciclico} se è chiuso rispetto alla rotazione, cioè se
  \[\forall z = z_1 z_2\ldots z_n \in Z, (z_n, z_1, \ldots, z_{n-1}) \in Z\]
\end{definition}

Per capire l'importanza dei codici ciclici è necessario spostarci dal campo \(\mathbb{F}_2^n\) al campo dei polinomi su \(\mathbb{F}_2\), ovvero \(\mathbb{F}_2[x]\).
Questo è possibile considerando ogni vettore \(\underline{u} = u_0 u_1 \ldots u_{n-2} u_{n-1} \in \mathbb{F}_2^n\) come i coefficienti del polinomio \(u(x) = u_0+u_1 x + \ldots+u_{n-2}x^{n-2}+ u_{n-1}x^{n-1} \in \mathbb{F}_2[x]\).

Prendendo in considerazione la rotazione di \(\underline{u}\), \(\underline{\hat{u}} = u_n u_0 u_1 \ldots u_{n-2}\) il polinomio corrispondente è
\[\hat{u}(x) = u_n + u_0 x + u_1 x^2 + \ldots + u_{n-2} x^{n-1} = u_{n-1} + x(u_0 + u_1 x + \ldots + u_{n-2} x^{n-2})\]

La somma nella parentesi corrisponde a \(u(x) - u_{n-1}x^{n-1}\), e dunque sostituendo si ottiene
\[\hat{u}(x) = u_{n-1} + x(u(x) - u_{n-1}x^{n-1}) = x u(x) - u_{n-1}(x^n-1)\]

Ovvero \(\hat{u}(x)\) e \(xu(x)\) coincidono a meno di un multiplo di \(x^n - 1\).
Vista tale equivalenza, consideriamo l'anello quoziente \(V^n[x] = \frac{\mathbb{F}_2[x]}{\langle x^n - 1\rangle}\).

Essendo che in questo anello \(x^n\equiv 1\) tutti i gradi dei polinomi sono ridotti modulo \(n\), dunque ogni elemento di \(V\) ha grado al più \(n-1\) e dunque corrisponde a un vettore di \(\mathbb{F}_2^n\).
Possiamo dunque costruire l'applicazione:
\[\begin{aligned}
  \psi: \mathbb{F}_2^n &\to V^n[x] \\
  \underline{u} \in \mathbb{F}_2^n &\mapsto u(x) = u_0 + u_1 x + \ldots + u_{n-1} x^{n-1}
\end{aligned}\]

Tale applicazione è biettiva, poiché ogni polinomio corrisponde a un unico vettore di \(\mathbb{F}_2^n\) è lineare (\(\psi(\underline{u} + \underline{v}) = \psi(\underline{u}) + \psi(\underline{v})\)) e tale che la rotazione di un vettore corrisponde alla moltiplicazione del polinomio per \(x\) in \(V^n[x]\).

\begin{definition}{Ideale}
  \(I \subseteq V^n[x]\) è detto \keyword{ideale} se
  \begin{enumerate}
    \item \(\forall u(x),v(x) \in I, u(x) + v(x) \in I\)
    \item \(\forall p(x) \in V^n[x], \forall u(x) \in I, p(x)u(x) \in I\)
  \end{enumerate}

  Ovvero se è chiuso internamente rispetto alla somma e chiuso rispetto alla moltiplicazione per qualsiasi elemento di \(V^n[x]\).
\end{definition}

% TODO: ask in un certo senso possiamo vedere l'ideale come uno spazio vettoriale con scalari in V?

\begin{note}{}
  Ovviamente \(V^n[x]\) è un ideale di se stesso.
\end{note}

\begin{lemma}{}
  \(Z \subseteq \mathbb{F}_2^n\) codice ciclico \(\iff\psi(Z) = \set{\psi(z)}[z\in Z]\) ideale di \(V^n[x]\).
\end{lemma}

\begin{proof}[Idea di Dimostrazione]
  Da destra a sinistra è semplice, poiché se \(\psi(Z)\) è un ideale è chiuso rispetto alla somma dunque \(Z\) è lineare e inoltre \(x\psi(z) \in \psi(Z)\) implica che la rotazione di \(z\) è in \(Z\).
  L'altro verso è più complesso, ma si mostra in modo simile.
\end{proof}

\begin{definition}{Ideali Principali}
  Un ideale è detto \keyword{principale} se esiste un polinomio \(g(x) \in V^n[x]\), detto \keyword{generatore} del principale, tale che
  \[I = \set{p(x)g(x)}[p(x) \in V^n[x]]\]
\end{definition}

\begin{example}{}
  Sia \(g(x) = 1 +x^2\) e determiniamo il codice ciclico \(Z \subseteq \mathbb{F}_2^3\) corrispondente all'ideale \(\langle g(x) \rangle \subseteq V^3[x]\).

  \begin{center}
    \begin{tabular}{c | c}
      \(p(x)\) & \(p(x)g(x)\) \\
      \hline
      \(0\) & \(0\) \\
      \(1\) & \(1+x^2\) \\
      \(x\) & \(x(1+x^2) \equiv 1 + x\) \\
      \(1+x\) & \((1+x)(1+x^2) \equiv x + x^2\) \\
      \(x^2\) & \(x^2(1+x^2) \equiv x + x^2\) \\
      \(1+x^2\) & \((1+x^2)(1+x^2) \equiv 1 + x\) \\
      \(x+x^2\) & \((x+x^2)(1+x^2) \equiv 1 + x^2\) \\
      \(1+x+x^2\) & \((1+x+x^2)(1+x^2) \equiv 0\) \\
    \end{tabular}
  \end{center}

  Dunque \(Z = \set{000,011,110,101}\).
\end{example}

% TODO: riguardo alla congettura di chiusura rispetto al "complemento" questa non è sempre vera. Credo che in questo caso funzioni perchè g(x) è in qualche modo simile ai polinomi per cui facciamo modulo (è il modulo di V^2[x]).

\begin{theorem}{}
  Tutti gli ideali di \(V^n[x]\) sono principali; in particolare \(\set{0} = \langle 0 \rangle\), e per \(I \neq \set{0}\) si ha \(I=\langle g(x)\rangle\) dove
  \[g(x) \in I\setminus\set{0} \text{ ha grado minimo}\] 

  Tale generatore è detto \keyword{generatore canonico} del principale \(I\).
\end{theorem}

\begin{note}{}
  La scelta del generatore canonico è unica:

  Se \(g(x), g'(x) \in I\setminus\set{0}\) sono entrambi di grado minimo, allora \(g(x)-g'(x)\in I\) e ha grado minore di entrambi, dunque \(g(x) - g'(x) = 0 \implies g(x) = g'(x)\).

  Nell'esercizio precedente, \(g(x) = 1 + x\) è il generatore canonico dell'ideale.
\end{note}

\begin{theorem}[label=thm:generator_divisor_zero]{}
  Sia \(Z \subseteq \mathbb{F}_2^n\) ciclico e sia \(g(x) \in \psi(Z)\) il generatore canonico di \(\psi(Z)\).
  Allora \(g(x)\) è un divisore di \(x^n - 1\).
\end{theorem}

\begin{proof}
  Consideriamo la divisione in \(\mathbb{F}_2[x]\)

  \[x^n - 1 = q(x)g(x) + r(x) \text{, con } r(x) = 0 \lor \deg(r) < \deg(g)\]

  In \(V^n[x]\) ciò comporta
  \[0 = q(x)g(x) +r(x) \implies r(x) = -q(x)g(x)\in \psi(Z) \implies r(x) = 0\]
\end{proof}

\begin{example}{}
  Sia \(n=7\). Si ha in \(\mathbb{F}_2[x]\),
  \[x^7-1=(1+x)(1+x+x^3)(1+x^2+x^3)\]
  come scomposizione in fattori irriducibili.

  Ciò corrisponde a \(2^3 = 8\) divisori, ovvero \(8\) codici ciclici distinti.
  Ad esempio \(\langle 1 \rangle = \psi(\mathbb{F}_2^7)\), \(\langle 0 \rangle = \set{0}\).

  Per \(g(x) = 1+x+x^3\), si ha \(x^7-1 = g(x)h(x)\), con \(h(x) = (1+x)(1+x^2+x^3)=1+x+x^2+x^4\)
\end{example}

\begin{theorem}{}
  Sia \(g(x)\) il generatore canonico di \(\psi(Z)\), con \(Z \subseteq \mathbb{F}_2^n\) ciclico di dimensione \(k\).
  Sia quindi \(h(x) = h_0+xh_1+\ldots h_k x^k\) tale che \(x^n-1=g(x)h(x)\), allora \(\deg(h(x))\) ha grado \(k\) e permette di ottenere una matrice di controllo \(H\) per \(Z\) come segue:

  \[H=\begin{pmatrix}
    h_k     & h_{k-1} & \ldots  & h_0     & 0   & \ldots & 0 \\
    0       & h_k     & h_{k-1} & \ldots  & h_0 & \ldots & 0 \\
    \vdots  &         &         & \ddots  &     &        & \vdots \\
    0       & \ldots  & 0       & h_k     & h_{k-1} & \ldots & h_0
  \end{pmatrix}\]
\end{theorem}

\begin{example}{}
  Dall'esempio precedente, con \(g(x) = 1+x+x^3\) e \(h(x) = 1+x+x^2+x^4\), otteniamo
  \[\begin{pmatrix}
    1 & 0 & 1 & 1 & 1 & 0 & 0 \\
    0 & 1 & 0 & 1 & 1 & 1 & 0 \\
    0 & 0 & 1 & 0 & 1 & 1 & 1 \\
  \end{pmatrix}\]

  Dato che le colonne di \(H\) sono tutte le possibili non nulle, \(Z\) è di Hamming.
\end{example}

\section{Codici BCH}

% TODO: in molti casi mi sembra si ignori l'edge case di polinomi = 1.
Se \(p(x) \in F_2[X]\) è irriducibile di grado \(m\), allora l'anello \(\frac{\mathbb{F}_2[x]}{\langle p(x) \rangle}\) è un campo, indicato come \(\mathbb{F}_{2^m}\).\footnote{Il motivo della doppia nomenclatura sarà chiaro a breve. Come piccola anticipazione, è possibile dire che i polinomi in \(\frac{\mathbb{F}_2[x]}{\langle p(x) \rangle}\) sono esattamente \(2^m\), tutti combinazioni lineari di potenze di \(x\) fino a \(m-1\) con coefficienti in \(\mathbb{F}_2\).}

\begin{note}{}
  Se \(p(x)\) è irriducibile, dal \Cref{thm:generator_divisor_zero} \(\frac{\mathbb{F}_2[x]}{\langle p(x) \rangle}\) ha come ideali solo \(\set{0}\) e se stesso, di generatore \(1\).
\end{note}

In questo caso in maniera simile a quanto si fa per la costruzione dei numeri complessi, possiamo denotare con \(\alpha\) una radice \qi{immaginaria} di \(p(x)\), ovvero \(p(\alpha) = 0\).
Dunque 
\[p_{m}\alpha^m+\ldots p_1\alpha+p_0 = 0\]

Essendo \(\deg p(x) = m\) almeno \(p_m\) è \(1\), e dunque possiamo riscrivere
\[\alpha^m = \sum_{0\leq j < m } p_j \alpha^j\]

Dunque la potenza \(m\)-esima di \(\alpha\) è esprimibile come combinazione lineare delle prime \(m\) potenze di \(\alpha\).

Moltiplicando entrambi i membri per \(\alpha\) modulo \(\alpha^{2m}\) è possibile ottenere tutte le potenze successive di \(\alpha\) fino a \(\alpha^{2^m-2}\) come combinazioni lineari delle prime \(m\) potenze di \(\alpha\), con la particolarità che \(\alpha^{2^m-1} = 1\).
Queste \(2^{m}-1\) potenze di alfa formano un gruppo moltiplicativo ciclico di ordine (o cardinalità) \(2^m-1\), che unito allo \(0\) formano il campo \(\mathbb{F}_{2^m}\).

Diremo in questo caso che \(\alpha\) è \keyword{radice primitiva} di \(\mathbb{F}_{2^m}\) se le sue potenze generano tutto il gruppo moltiplicativo.

Tramite un analogo di \(\psi^{-1}\) inoltre, è possibile considerare ogni elemento di \(\mathbb{F}_{2^m}\) come un vettore di \(\mathbb{F}_2^m\) e viceversa.
\[\begin{aligned}
  \psi^{-1}: \mathbb{F}_{2^m} &\to \mathbb{F}_2^m \\
  u_0 + u_1 \alpha + u_2 \alpha^2 + \ldots + u_{m-1} \alpha^{m-1} &\mapsto u_0 u_1 u_2 \ldots u_{m-1}
\end{aligned}\]

\begin{example}{}
  Consideriamo il polinomio \(1+x+x^3\) irriducibile su \(\mathbb{F}_2\), e il relativo campo quoziente \(\mathbb{F}_8 = \frac{\mathbb{F}_2[x]}{\langle 1 + x +x^3 \rangle}\).
  
  Sia \(\alpha\) una radice di \(1+x+x^3\), ovvero \(\alpha^3= \alpha + 1\).

  Abbiamo dunque
  \[\alpha^0 = 1\]
  \[\alpha^1 = \alpha\]
  \[\alpha^2 = \alpha^2\]
  \[\alpha^3 = \alpha + 1\]
  \[\alpha^4 = \alpha^2+\alpha\]
  \[\alpha^5 = \alpha^3 + \alpha^2 = \alpha^2+\alpha+1\]
  \[\alpha^6 = \alpha^4 + \alpha^3 = \alpha + 1 + \alpha^2 + \alpha = \alpha^2 + 1\]
  \[\alpha^7 = \alpha^5 + \alpha^4 = \alpha^2+\alpha+1+\alpha^2+\alpha = 1\]

  Quindi \(\mathbb{F}_8 = \set{0} \cup \set{\alpha^i}[i=0,\ldots,6]\). 
\end{example}

Prendiamo dunque un polinomio irriducibile \(q(x) \in \mathbb{F}_2[x]\) di grado \(m\), e sia \(\alpha\) una sua radice.

Essendo il gruppo moltiplicativo di \(\mathbb{F}_{2^m}\) ciclico di ordine \(2^m-1\), questo conterrà le potenze di \(\alpha\) fino a \(\alpha^{2^m-2}\), e dunque \(\alpha^{2^m-1} = 1\), da cui \(\alpha^{2^m-1}-1=0\).
Di conseguenza, il polinomio \(x^{n}-1\) avrà \(\alpha\) come radice, per \(n = 2^m -1\).

Inoltre, prendendo una qualsiasi potenza di \(\alpha\), \(\alpha^i\) con \(0 \leq i \leq n-1\), si ha che
\[{(\alpha^i)}^n - 1 = {(\alpha^n)}^i - 1 = 1^i - 1 = 0\]
Dunque tutti gli elementi del gruppo moltiplicativo di \(\mathbb{F}_{2^m}\) sono radici di \(x^n - 1\).

Possiamo dunque scrivere in \(\mathbb{F}_{2^m}[x]\)
\[x^n - 1 = \prod_{i=0}^{n-1} (x - \alpha^i)\]

Se tale polinomio è riducibile in \(\mathbb{F}_2[x]\), possiamo considerare la sua scomposizione in fattori irriducibili. Essendo che \(1\) è sicuramente una radice, la sua scomposizione in fattori irriducibili avrà la forma
\[x^n - 1 = (x-1)f_1(x)\ldots f_l(x)\]

Essendo che \(\mathbb{F}_2 \subseteq \mathbb{F}_{2^m}\), possiamo scrivere la seguente espressione in \(\mathbb{F}_{2^m}[x]\):
\[(x-1)f_1(x)\ldots f_l(x) = \prod_{i=0}^{n-1} (x - \alpha^i) = (x-1)(x-\alpha)\ldots(x-\alpha^{n-1})\]
\[f_1(x)\ldots f_l(x) = (x-\alpha)\ldots(x-\alpha^{n-1})\]

% Dunque ogni \(f_j(x)\) avrà come radici alcune delle potenze di \(\alpha\).
Possiamo osservare un altra importante proprietà dei polinomi in \(\mathbb{F}_2[x]\), ovvero che se \(\beta\) è radice di un polinomio \(p(x) \in \mathbb{F}_2[x]\), allora anche \(\beta^2\) è radice di \(p(x)\).
Questo poiché in \(\mathbb{F}_2\) vale che \({(a+b)}^2 = a^2 + b^2\) e \(a^2 = a\) per ogni \(a,b \in \mathbb{F}_2\).
Dunque se un polinomio \(p(x) = p_0 + p_1 x + \ldots p_h x^h\) ha \(\beta\) come radice, si ha
\[p(\beta) = p_0 + p_1 \beta + p_2 \beta^2 + \ldots + p_h \beta^h = 0\]
Elevando al quadrato entrambi i membri si ottiene da \({(a+b)}^2 = a^2 + b^2\) che
\[0^2 = p_0^2 + p_1^2 \beta^2 + p_2^2 \beta^4 + \ldots + p_h^2 \beta^{2h} \]
Inoltre essendo tutti i coefficienti \(p_i \in \mathbb{F}_2\) si ha che \(p_i^2 = p_i\), dunque
\[0 = p_0 + p_1 \beta^2 + p_2 \beta^4 + \ldots + p_h \beta^{2h} = p(\beta^2)\]
Dunque \(\beta^2\) è anch'essa radice di \(p(x)\).

Di conseguenza, il nostro \(q(x)\) da cui abbiamo costruito \(\mathbb{F}_{2^m}\) essendo irriducibile in \(\mathbb{F}_2[x]\) avrà tutte e sole le sue radici in \(\mathbb{F}_{2^m}\), ovvero tutti gli elementi della forma \(\alpha^{i}\), con \(i \equiv_{2^m-1} 2^j\) per \(j \geq 0\).
Possiamo dunque scrivere \(q(x) = \prod_{i=0}^{m} (x-\alpha^{2^i})\).

Dunque \(q(x)\) è uno dei fattori irriducibili \(f_j(x)\) di \(x^n - 1\) in \(\mathbb{F}_2[x]\).\footnote{Avendo preso un polinomio di grado \(m\) qualsiasi, lo stesso ragionamento vale per ogni polinomio irriducibile di grado \(m\). Dunque tutti i polinomi irriducibili di grado \(m\) dividono \(x^n-1\) per \(n=2^m-1\).}

Senza perdita di generalità, supponiamo che \(q(x) = f_1(x)\).
Possiamo cancellare dall'equazione precedente il fattore \(q(x)\) e le sue radici, ottenendo
\[ f_2(x)\ldots f_l(x) = \prod_{\substack{i=0 \\ i \not\equiv_{n} 2^k\\k \geq 0}}^{n-1} (x - \alpha^i)\]

Lo stesso ragionamento può essere fatto per ogni \(f_j(x)\), che avrà come radici alcune potenze di \(\alpha\) e tutte le loro potenze successive di \(2\).
Di conseguenza ogni \(\alpha^i\) sarà radice di uno e un solo \(f_j(x)\).
Per ogni \(\alpha^i\), chiameremo tale polinomio \(m_i(x)\), ovvero il \keyword{polinomio minimo} di \(\alpha^i\) su \(\mathbb{F}_2\).

Fissato \(d'< n\), consideriamo il codice ciclico il cui generatore canonico è\footnote{È sicuro che tale polinomio sia un generatore canonico poiché essendo prodotto di fattori di \(x^n-1\) divide anch'esso \(x^n-1\).}
\[\operatorname{lcm}(m_1(x), m_2(x), \ldots, m_{d'-1}(x))\]
Per loro costruzione, tali \(m_i(x)\) non hanno fattori in comune, dunque il loro minimo comune multiplo è il loro prodotto.
Si considera comunque il minimo comune multiplo poiché, indicizzati in base all'esponente della radice, più \(m_i(x)\) possono coincidere, in particolare \(m_i(x) = m_j(x)\) se \(i \equiv_{n} 2^k j\) per qualche \(k \geq 0\).

Se ad esempio \(f_i(x) = (x-\alpha)(x-\alpha^2)(x-\alpha^4)\) allora \(m_1(x) = m_2(x) = m_4(x) = f_i(x)\). Di conseguenza, per \(d' \geq 5\), \(m_1(x), m_2(x), m_4(x)\) compariranno tutti nella lista dei polinomi minimi da considerare per il generatore canonico.
Usare il minimo comune multiplo evita dunque di contare più volte lo stesso fattore.

Tale codice è detto codice \(BCH\) con distanza designata \(d'\).

\begin{note}{}
  \(BCH\) sta per Bose-Chaudhuri-Hocquenghem, i nomi dei tre inventori di questi codici nel 1959--60.
\end{note}

\begin{theorem}{}
  Se \(n = 2^m-1\) e \(d' = 2t+1\), allora il codice \(BCH\) di distanza designata \(d'\) verifica
  \begin{itemize}
    \item \(k\geq n-tm\) e \(\delta \geq d'\) (dunque hanno distanza arbitrariamente grande e tasso arbitrariamente vicino a \(1\))
    \item una matrice di controllo \(H\) può essere costruita da quella \(2t\times n\) su \(\mathbb{F}_{2^m}\)
  \end{itemize}
  \[\begin{pmatrix}
    \alpha^0 & \alpha^1 &\ldots &\alpha^{n-1}\\
    \alpha^{0\cdot 2} & \alpha^{1\cdot 2} &\ldots &\alpha^{(n-1)\cdot 2}\\
    \vdots & & & \vdots \\
    \alpha^{0\cdot 2t} & \alpha^{1\cdot 2t} &\ldots &\alpha^{(n-1)\cdot 2t}
  \end{pmatrix}\]
  sostituendo a ogni \(\alpha^i\) il corrispondente vettore (colonna) in \(\mathbb{F}_2^m\).
\end{theorem}

\begin{example}{}
  Sia \(n = 15 = 2^4-1\). Allora
  \[x^{15}=(x+1)(x^2+x+1)(x^4+x+1)(x^4+x^3+1)(x^4+x^3+x^2+x+1)\]

  Per correggere \(t = 2\) errori, è necessario avere \(d' = 2t+1 = 5\).
  Per costruzione dei \(BCH\), sono necessari i polinomi minimi di \(\alpha^1, \alpha^2, \alpha^3, \alpha^4\).
  Sia dunque \(\alpha\) una radice primitiva di \(x^4+x+1\) in \(\mathbb{F}_{16}\).
  
  Si ha che \(m_1(x), m_2(x)\) e \(m_4(x)\) derivano facilmente dall'osservazione precedente che se \(\beta\) è radice di un polinomio in \(\mathbb{F}_2[x]\), allora anche \(\beta^2\) lo è.
  Per \(m_3(x)\) va verificato quale fattore di \(x^n-1\) ha \(\alpha^3\) come sua radice. In questo caso, possiamo facilmente vedere che si tratta di \(x^4+x^3+x^2+x+1\), poiché
  \[\begin{aligned}
    {(\alpha^3)}^4 + {(\alpha^3)}^3 + {(\alpha^3)}^2 + \alpha^3 + 1 &= \alpha^{12} + \alpha^9 + \alpha^6 + \alpha^3 + 1\\
  \end{aligned}\]
  Abbiamo per costruzione di \(\mathbb{F}_{16}\) che
  \[\alpha^6 = \alpha^3 + \alpha^2\]
  \[\alpha^9 = \alpha^6 + \alpha^5 = \alpha^3 + \alpha + \alpha^2\]
  \[\alpha^{12} = \alpha^9 + \alpha^8 = \alpha^2 + 1 + \alpha^3 + \alpha + \alpha^2 = \alpha^3 + \alpha + 1\]
  Dunque
  \[\alpha^{12} + \alpha^9 + \alpha^6 + \alpha^3 + 1 = (\alpha^3 + \alpha + 1) + (\alpha^3 + \alpha + \alpha^2) + (\alpha^3 + \alpha^2) + \alpha^3 + 1 = 0\]

  Dunque il generatore canonico è
  \[g(x) = \operatorname{lcm}(m_1(x), m_2(x), m_3(x), m_4(x)) = m_1(x)m_3(x) = x^8 + x^7 + x^6 + x^4 + 1\]

  Possiamo costruire un codice \(BCH\) che corregge \(t=2\) errori da
  \[\begin{pmatrix}
    \alpha^0 & \alpha^1 & \alpha^2 \ldots \alpha^{14}\\
    \alpha^0 & \alpha^3 & \alpha^6 \ldots \alpha^{12}
  \end{pmatrix}\]

  Le altre \(2\) righe corrispondono a polinomi già rappresentati\footnote{In generale tutte le righe pari sono superflue}. Questo ci dà\footnote{
    La matrice sottostante è stata riempita con l'ausilio di AI generativa. Non si assicura la correttezza di tutti i numeri presenti.
  }

  \[
H = \left(
\begin{array}{ccccccccccccccc}
% --- Prime 6 colonne (0-5) --- % & % --- Colonne richieste (6-14) --- %
1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 1 \\
0 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 0 \\
0 & 0 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 1 & 1 & 1 & 1 \\
\hline
1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 1 \\
0 & 0 & 1 & 0 & 1 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 \\
0 & 1 & 1 & 1 & 0 & 0 & 1 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 \\
\end{array}
\right)
\]

  Tasso \(R = \frac{k}{n} = \frac{7}{15}\), \(\delta = 5\)
\end{example}