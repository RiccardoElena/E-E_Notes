\chapter{Lezione 30 Ottobre}

Lunedì salta, ma dobbiamo recuperare almeno questa.
Eventualmente un venerdì nell'orario originale.

\begin{theorem}{}
  Sia \(S\) sorgente e \(A\) alfabeto di codice con \(\# A = d \geq 2\).
  Allora esiste \(X\) codice prefisso su \(A\) adattato a \(S\) tale che
  \[\frac{H(S)}{\log\left(d\right)} \leq c(X) < \frac{H(S)}{\log\left(d\right)} + 1.\]
\end{theorem}

Ovvero si discosta dal costo dell'assolutamente ottimale di al più \(1\).
\begin{observation}{}
  In generale non è detto che un codice finito ammetta completamento finito.
  Per i codici prefisso invece sì. Questo poiché essere massimale per un codice prefisso è equivalente all'esistenza di un albero completo.
  Dunque se non è massimale, posso aggiungere nodi fino a renderlo completo.
\end{observation}

\begin{example}{}
  Sia \(X = \set{a,ba,bba,b^4}\) codice binario prefisso.
  

  INSERIRE ALBERO
\end{example}

\begin{algorithmdesc}{Codici di Huffman}
  Sia \(S = (\SCal,p)\) sorgente con \(\SCal = \set{s_1, \ldots, s_k}\) e sia \(\forall i \in \set{1,\ldots,k}, p_i=p(s_i)\), supponendo \(p_1 \geq p_2 \geq \ldots \geq p_k\).
  Allora se \(X\) è codice binario adattato a \(S\), e \(X = \set{x_1,\ldots,x_k}\) tale che \(\varphi(s_i) = x_i\) con \(\varphi\) codifica che realizza il costo minimo, si ha che \(\abs{x_1}\leq\abs{x_2}\leq\ldots\leq\abs{x_k}\).

  Se \(X\) è prefisso e ottimale per \(S\), allora è massimale. 
  Poiché allora \(T_x\) è completo nell'ultimo livello il numero di foglie è pari, poiché tutti i nodi al livello precedente devono avere due figli.
  Dunque tutte le parole associate a tali foglie hanno la stessa lunghezza.
  Assumiamo dunque senza perdita di generalità\footnote{Non c'è perdita di generalità poiché tutte le parole associate alle foglie dell'ultimo livello avendo la stessa lunghezza possono essere permutate nella successione \(\abs{x_1}\leq\abs{x_2}\leq\ldots\leq\abs{x_k}\) senza alterarne il significato.} che \(x_k\) e \(x_{k-1}\) siano figlie dello stesso nodo, esiste \(x_{k-1,k}\in Pref(X)\), massimo prefisso comune, tale che \(x_{k-1} = x_{k-1}a\) e \(x_k = x_{k-1}b\) con \(a,b \in A, a \neq b\).

  L'idea dell'algoritmo è passare a una sorgente ridotta \(S_{k-1}\), tale che \(\SCal_{k-1} = \set{s_1,\ldots,s_{k-2}, s_{k-1,k}}\) con \(p(s_i)=pi, \forall i \in \set{1,\ldots,k-2}\) e \(p_{k-1,k} = p_{k-1} + p_k\), dove \(s_{k-1,k}\) è un nuovo simbolo che sostituisce \(s_{k-1}\) e \(s_k\).
  A tale sorgente viene adattato il codice \(X_{k-1} = \set{x_1,\ldots,x_{k-2}, x_{k-1,k}}\).
  L'albero di codice \(T_{x_{k-1,k}}\) rimane ovviamente completo e quindi il codice rimane massimale.
  Dimostreremo che allora \(X_{k-1}\) è ottimale per \(S_{k-1}\) se e solo se \(X\) è ottimale per \(S\).

  Dimostrato questo possiamo definire una procedura iterando il procedimento fino a ottenere una sorgente con due soli simboli, per la quale l'ottimo è banale da calcolare.
  Infatti, in tal caso l'unico codice prefisso ottimale è \(X_2 = \set{a,b}\) con \(a,b \in A, a \neq b\).
  Da lì, avendo tenuto traccia delle \qi{fusioni} operate, potremmo ottenere il codice \(X_3\) ottimale per \(S_3\) e così via fino a risalire a \(X\).
\end{algorithmdesc}

\begin{example}{}
  Sia \(\SCal = \set{s_1,\ldots, s_6}\) e \(p_1 = 0.3,p_2=0.25,p_3=0.2,p_4=p_5=0.1,p_6=0.05\). Costruiamo dunque un\footnote{Da notare che si andrà a trovare \qi{un} codice e non \qi{il} codice, poiché nella procedura sono presenti punti in cui vanno effettuate scelte arbitrarie, che possono portare alla generazione di codici diversi, ugualmente ottimali} codice di Huffman per \(S\).
  Allora una prima sorgente ridotta potrebbe essere \(S_5\) con \(\SCal_5 = \set{s_1,s_2,s_3,s_4,s_{5,6}}\) con \(p_{5,6} = 0.15\). Dunque \(p_3 = 0.2 > p_{5,6} > p_4 = 0.1\).
  La successiva riduzione darà quindi \(\SCal_4 = \set{s_1,s_2,s_{3},s_{4,5,6}}\) con \(p_{4,5,6} = 0.25\). Ora \(p_2 = p_{4,5,6} = 0.25 > p_3\).
  Scegliamo dunque di formare \(\SCal_3 = \set{s_1,s_{2,3},s_{4,5,6}}\) con \(p_{2,3} = 0.45\).
  Infine siamo a \(\SCal_2 = \set{s_{2,3}, s_{1,4,5,6}}\) con \(p_{1,4,5,6} = 0.55\).
  A questo punto per individuare il codice sarà sufficiente risalire le fusioni al contrario.

  INSERIRE FOTO ALBERI PROGRESSIVI.

  Dunque \(\set{a^2,ab,ba,b^2a,b^3a,b^4}\) è ottimale per \(S\). Inoltre l'algoritmo fornisce anche una codifica che realizza il costo ottimale.
\end{example}

La correttezza dell'algoritmo si basa su due osservazioni fondamentali:
\begin{enumerate}
  \item \(X\) codice prefisso (massimale) su \(A\), \(x \in X \implies X \setminus \set{x} \cup \set{x}A\) codice prefisso (massimale).
  \item \(X\) codice prefisso (massimale) su \(A\) e \(\exists x' \st \set{x'}A \subseteq X \implies X\setminus \set{x'}A \cup \set{x'}\) codice prefisso (massimale).
 \end{enumerate}

Dobbiamo dunque dimostrare che se \(X_i\) è ottimale per \(S_i\), con \(2\leq i \leq k-1\) allora \(X_{i+1}\) è ottimale per \(S_{i+1}\) e viceversa.

Assumiamo \(X_i = \set{z_1, \ldots,z_i}\) e \(X_{i+1} = \set{z_1,\ldots,z_{i-1},z_{i}a, z_{i}b}\), con queste ultime associate a simboli di probabilità \(q_1\geq q_2 \geq \ldots \geq q_{i-1} \geq q_i \geq q_{i+1}\) e \(z_i\) associata a un simbolo di \(S_i\) di probabilità \(q_i + q_{i+1}\).
Supponiamo per assurdo che \(X_{i+1}\) non sia ottimale per \(S_{i+1}\) e sia \(X'_{i+1} \) prefisso ottimale (binario) per \(S_{i+1}\).
Poiché \(X'_{i+1}\) è ottimale, è massimale e dunque \(T_{X'_{i+1}}\) è completo. Dunque esistono \(z_i', z_{i+1}' \in X'_{i+1}\) tali che \(z_i' = z_{i,i+1}'a\) e \(z_{i+1}' = z_{i,i+1}'b\) con \(a,b \in A, a \neq b\).
Nel calcolo di \(c(X_{i+1}')\) tali parole dovranno essere associate a simboli di probabilità \(q_i\) e \(q_{i+1}\).
Sia allora \(X_{i+1}' = \set{z_1',\ldots,z_{i-1}'}, z_i'=z_{i,i+1}'a,z_{i+1}' = z_{i,i+1}'b\) e definiamo \(X_i' = \set{z_1',\ldots,z_{i-1}', z_{i,i+1}'}\).
Si ha \(c(X_i') \leq \sum_{j=1}^{i-1} q_j\abs{z_i'} + (q_i+q_{i+1})\abs{z_{i,i+1}'}\).
Possiamo osservare che \(\abs{z_{i,i+1}'} = \abs{z_{i}}-1 = \abs{z_{i+1}}-1\).
Dunque
\[c(X_i') \leq \sum_{j=1}^{i-1} q_j\abs{z_i'} + q_i(\abs{z_{i}}-1) + q_{i+1}(\abs{z_{i+1}}-1) = \]
\[=\sum_{j=1}^{i+1} q_j\abs{z_j'} - (q_i + q_{i+1}) = c(X_{i+1}') - (q_i + q_{i+1}) < c(X_{i+1}) - (q_i + q_{i+1})\]

Ma il codic \(X_i\) è ottenuto da \(X_{i+1}\) nello stesso modo in cui \(X_i'\) è ottenuto da \(X_{i+1}'\).
Dunque \(c(X_i') \leq c(X_{i+1}') - (q_i + q_{i+1}) < c(X_{i+1}) - (q_i + q_{i+1}) = \sum_{j=1}^{i+1} q_j\abs{z_j} - (q_i + q_{i+1})\).
Avendo detto che \(X_i\) è ottimale per \(S_i\), ed è ottenuto associando a \(z_i\) un simbolo di probabilità \(q_i + q_{i+1}\), si ha che
\[c(X_i') \leq c(X_{i+1}') - (q_i + q_{i+1}) < c(X_{i+1}) - (q_i + q_{i+1}) = \sum_{j=1}^{i+1} q_j\abs{z_j} - (q_i + q_{i+1}) = \]
\[=\sum_{j=1}^{i-1} q_j\abs{z_j} + q_i(\abs{z_i a}-1) + q_{i+1}(\abs{z_{i+1}b}-1) = \sum_{j=1}^{i-1} q_j\abs{z_j} + (q_i+q_{i+1})\abs{z_{i}} = c(X_i)\]

Abbiamo dunque trovato che \(c(X_i')<c(X_i)\) che contraddice l'ipotesi che \(X_i\) sia ottimale per \(S_i\).